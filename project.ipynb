{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5fc7660",
   "metadata": {},
   "source": [
    "# AI Project: Employee Attrition Prediction - **source code**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6ddf6c",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Framework](#framework)\n",
    "- [Initial dataset](#initial-dataset)\n",
    "- [Ethic](#ethic)\n",
    "- [Data wrangling](#data-wrangling)\n",
    "- [Model](#model)\n",
    "  - [Implementation](#implementation)\n",
    "  - [Quality indicators](#quality-indicators)\n",
    "  - [Graph and observation](#graph-and-observation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d083188",
   "metadata": {},
   "source": [
    "## Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "393f4109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1ec250",
   "metadata": {},
   "source": [
    "## Initial dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cecc590",
   "metadata": {},
   "source": [
    "little description of the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480dbfa2",
   "metadata": {},
   "source": [
    "## Ethic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceec6734",
   "metadata": {},
   "source": [
    "blabla ethic\n",
    "What we delete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c149324",
   "metadata": {},
   "source": [
    "## Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d4dc97",
   "metadata": {},
   "source": [
    "### Data importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ed3c4a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "general_df = pd.read_csv(os.path.join('data','general_data.csv'))\n",
    "manager_survey_df = pd.read_csv(os.path.join('data', 'manager_survey_data.csv'))\n",
    "employee_survey_df = pd.read_csv(os.path.join('data', 'employee_survey_data.csv'))\n",
    "in_time = pd.read_csv(os.path.join('data', 'in_time.csv'))\n",
    "out_time = pd.read_csv(os.path.join('data', 'out_time.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d84bfa5",
   "metadata": {},
   "source": [
    "### Data observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f8ccfef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check initial data sizes\n",
    "print(f\"General Data: {general_df.shape} (rows, columns)\")\n",
    "print(f\"Manager Survey: {manager_survey_df.shape}\")\n",
    "print(f\"Employee Survey: {employee_survey_df.shape}\")\n",
    "\n",
    "\n",
    "print(\"\\n===========================================================\\n\")\n",
    "\n",
    "\n",
    "# Check if EmployeeID has duplicates\n",
    "if general_df['EmployeeID'].duplicated().sum() == 0:\n",
    "    print(\"EmployeeID is unique\")\n",
    "else:\n",
    "    print(\"Warning\")\n",
    "\n",
    "\n",
    "print(\"\\n===========================================================\\n\")\n",
    "\n",
    "\n",
    "# Merge data\n",
    "merge_df = pd.merge(general_df, manager_survey_df, on='EmployeeID', how='left')\n",
    "final_df = pd.merge(merge_df, employee_survey_df, on='EmployeeID', how='left')\n",
    "\n",
    "print(f\"Size of Final Table: {final_df.shape}\")\n",
    "\n",
    "\n",
    "print(\"\\n===========================================================\\n\")\n",
    "\n",
    "\n",
    "print(f\"First 5 rows:\")\n",
    "display(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eeee285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check initial data sizes\n",
    "print(f\"In time: {in_time.shape} (rows, columns)\")\n",
    "print(f\"Out time: {out_time.shape}\")\n",
    "\n",
    "# Rename first column to 'EmployeeID' for consistency\n",
    "in_time.rename(columns={in_time.columns[0]: 'EmployeeID'}, inplace=True)\n",
    "out_time.rename(columns={out_time.columns[0]: 'EmployeeID'}, inplace=True)\n",
    "\n",
    "# Set 'EmployeeID' as index\n",
    "in_time.set_index('EmployeeID', inplace=True)\n",
    "out_time.set_index('EmployeeID', inplace=True)\n",
    "\n",
    "# Change data into datetime. errors='coerce' if (NaT)\n",
    "in_time_df = in_time.apply(pd.to_datetime, errors='coerce')\n",
    "out_time_df = out_time.apply(pd.to_datetime, errors='coerce')\n",
    "\n",
    "# Calculate working time\n",
    "working_time = out_time_df - in_time_df\n",
    "display(working_time.head())\n",
    "\n",
    "\n",
    "print(\"\\n===========================================================\\n\")\n",
    "\n",
    "\n",
    "# Check average working time\n",
    "average_working_time = working_time.mean(axis=1)\n",
    "avg_working_hours_numeric = average_working_time.apply(lambda x: x.total_seconds() / 3600)\n",
    "display(avg_working_hours_numeric.head())\n",
    "\n",
    "\n",
    "print(\"\\n===========================================================\\n\")\n",
    "\n",
    "\n",
    "# Reset index to turn Series into DataFrame\n",
    "time_features_df = avg_working_hours_numeric.reset_index()\n",
    "# Rename columns\n",
    "time_features_df.columns = ['EmployeeID', 'AvgWorkingHours']\n",
    "# Display final time features DataFrame\n",
    "display(time_features_df.head())\n",
    "\n",
    "\n",
    "print(\"\\n===========================================================\\n\")\n",
    "\n",
    "\n",
    "# Merge time features back to final_df\n",
    "final_df = pd.merge(final_df, time_features_df, on='EmployeeID', how='left')\n",
    "# Check final data sizes\n",
    "print(f\"Final DataFrame: {final_df.shape} (rows, columns)\")\n",
    "\n",
    "\n",
    "print(\"\\n===========================================================\\n\")\n",
    "\n",
    "\n",
    "print(\"First 5 rows of final DataFrame:\")\n",
    "display(final_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9180ca",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a0b695da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unneeded columns\n",
    "columns_to_drop = ['EmployeeCount', 'Over18', 'StandardHours']\n",
    "final_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Handle missing values\n",
    "numeric_columns = final_df.select_dtypes(include=[np.number]).columns\n",
    "final_df[numeric_columns] = final_df[numeric_columns].fillna(final_df[numeric_columns].mean()) \n",
    "missing_values = final_df.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "\n",
    "print(\"\\n===========================================================\\n\")\n",
    "\n",
    "\n",
    "# Label encoding \n",
    "attrition_map = {'Yes': 1, 'No': 0}\n",
    "final_df['Attrition'] = final_df['Attrition'].map(attrition_map)\n",
    "gender_map = {'Male': 1, 'Female': 0}\n",
    "final_df['Gender'] = final_df['Gender'].map(gender_map)\n",
    "travel_map = {\n",
    "    'Non-Travel': 0,\n",
    "    'Travel_Rarely': 1,\n",
    "    'Travel_Frequently': 2\n",
    "}\n",
    "final_df['BusinessTravel'] = final_df['BusinessTravel'].map(travel_map)\n",
    "\n",
    "# One-hot encoding\n",
    "categorical_columns = final_df.select_dtypes(include=['object']).columns\n",
    "final_df = pd.get_dummies(final_df, columns=categorical_columns, drop_first=True)\n",
    "final_df = final_df.replace({True: 1, False: 0})\n",
    "print(final_df.info())\n",
    "print(\"\\n===========================================================\\n\")\n",
    "print(\"First 5 rows after encoding:\")\n",
    "print(\"\\n\")\n",
    "display(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correlation_heatmap_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = final_df.corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(24, 18)) \n",
    "sns.heatmap(corr_matrix, \n",
    "            annot=True,       \n",
    "            fmt=\".2f\",        \n",
    "            cmap=\"coolwarm\",  \n",
    "            linewidths=0.5,   \n",
    "            vmin=-1, vmax=1)  \n",
    "\n",
    "plt.title(\"Correlation Matrix\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "17d378af",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(os.path.join('data', 'final_data_processed.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4a09ab",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e41add",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ec98aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implemente the model\n",
    "# with  pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eedace",
   "metadata": {},
   "source": [
    "### Quality indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a16b387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE, MAE RMSE, RÂ²\n",
    "# Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899a70b9",
   "metadata": {},
   "source": [
    "### Graph and observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "22c69423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt if we have"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
